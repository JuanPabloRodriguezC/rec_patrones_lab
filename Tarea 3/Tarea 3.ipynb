{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerceptronMulticapa:\n",
    "    def __init__(self, capas, alpha=0.1):\n",
    "        self.capas = capas\n",
    "        self.alpha = alpha\n",
    "        self.bias = []\n",
    "        self.pesos = []\n",
    "        for i in range(0, len(capas) - 1):\n",
    "            # Inicializar los pesos y bias de cada capa\n",
    "            peso = np.random.randn(capas[i], capas[i+1]) * np.sqrt(2.0 / capas[i])\n",
    "            self.pesos.append(peso)\n",
    "            bias = np.zeros(capas[i+1])\n",
    "            self.bias.append(bias)\n",
    "\n",
    "    def activacion(self, x, activacion):\n",
    "        match activacion:\n",
    "            case \"tanh\":\n",
    "                return np.tanh(x)\n",
    "            case \"sigmoid\":\n",
    "                return 1 / (1 + np.exp(-x))\n",
    "            case \"relu\":\n",
    "                return np.maximum(0, x)\n",
    "            case \"lineal\":\n",
    "                return x\n",
    "            case \"softmax\":\n",
    "                e_x = np.exp(x - np.max(x))\n",
    "                return e_x / np.sum(e_x)\n",
    "\n",
    "    def activacion_derivada(self, x, activacion):\n",
    "        match activacion:\n",
    "            case \"tanh\":\n",
    "                return 1 - x ** 2\n",
    "            case \"sigmoid\":\n",
    "                return x * (1 - x)\n",
    "            case \"relu\":\n",
    "                return (x > 0).astype(float)\n",
    "            case \"lineal\":\n",
    "                return np.ones_like(x)\n",
    "            case \"softmax\":\n",
    "                return np.ones_like(x)\n",
    "\n",
    "    def feedforward(self, X):\n",
    "        # Calcular la salida de cada capa\n",
    "        capa_activacion = [X]\n",
    "        for i in range(len(self.capas) - 1):\n",
    "            x = np.dot(capa_activacion[i], self.pesos[i]) + self.bias[i]\n",
    "            y = self.activacion(x)\n",
    "            capa_activacion.append(y)\n",
    "        return capa_activacion\n",
    "\n",
    "    def backpropagation(self, X, y, capa_activacion):\n",
    "        # Calcular el error de la capa de salida\n",
    "        if self.activaciones[-1] == \"softmax\":\n",
    "            delta = capa_activacion[-1] - y  # Already the correct gradient\n",
    "        else:\n",
    "            error = capa_activacion[-1] - y\n",
    "            delta = error * self.activacion_derivada(capa_activacion[-1])\n",
    "        deltas = [delta]\n",
    "\n",
    "        for i in reversed(range(1, len(self.capas) - 1)):\n",
    "            delta = np.dot(deltas[0], self.pesos[i].T) * self.activacion_derivada(capa_activacion[i])\n",
    "            deltas.insert(0, delta) \n",
    "        \n",
    "        # Propagar el error hacia atr谩s a trav茅s de la red neuronal\n",
    "        for i in range(len(self.pesos)):\n",
    "            a = capa_activacion[i].reshape(-1, 1)\n",
    "            d = deltas[i].reshape(1, -1)\n",
    "            self.pesos[i] -= self.alpha * np.dot(a, d)\n",
    "            self.bias[i] -= self.alpha * deltas[i]\n",
    "\n",
    "    def entrenar(self, X, y, epochs):\n",
    "        inicio = time.time()\n",
    "        for epoch in range(epochs):\n",
    "            for i in range(len(X)):\n",
    "                # Feedforward\n",
    "                capa_activacion = self.feedforward(X[i])\n",
    "\n",
    "                # Backpropagation\n",
    "                self.backpropagation(X[i], y[i], capa_activacion)\n",
    "            if (epoch+1) % 10 == 0:\n",
    "                print(f\"Epoch {epoch+1}/{epochs} completado\")\n",
    "        fin = time.time()\n",
    "        return fin - inicio\n",
    "\n",
    "    def predecir(self, X):\n",
    "        # Obtener la salida de la 煤ltima capa\n",
    "        capa_activacion = self.feedforward(X)\n",
    "        return capa_activacion[-1]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "X = mnist.data.astype(np.float32)\n",
    "y = mnist.target.astype(int)\n",
    "\n",
    "# Normalizar a rango [0,1]\n",
    "X /= 255.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estandarizar los datos (media 0, varianza 1)\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# One-hot encoding de las etiquetas\n",
    "Y = np.eye(10)[y]\n",
    "\n",
    "# Dividir en entrenamiento y prueba\n",
    "X_entrenamiento, X_prueba, y_entrenamiento, y_prueba = train_test_split(\n",
    "    X, Y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crear y entrenar la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50 completado\n",
      "Epoch 20/50 completado\n",
      "Epoch 30/50 completado\n",
      "Epoch 40/50 completado\n",
      "Epoch 50/50 completado\n"
     ]
    }
   ],
   "source": [
    "perceptron = PerceptronMulticapa(capas=[784, 128, 64, 10], alpha=0.01)\n",
    "tiempo_entrenamiento = perceptron.entrenar(X_entrenamiento, y_entrenamiento, epochs=50)\n",
    "\n",
    "# Evaluar con un subconjunto (por tiempo)\n",
    "predicciones = []\n",
    "y_reales = []\n",
    "\n",
    "for i in range(500):\n",
    "    salida = perceptron.predecir(X_prueba[i])\n",
    "    pred_clase = np.argmax(salida)\n",
    "    real_clase = np.argmax(y_prueba[i])\n",
    "    predicciones.append(pred_clase)\n",
    "    y_reales.append(real_clase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Resultados del modelo:\n",
      "Accuracy:  0.7600\n",
      "Precision: 0.7692\n",
      "Recall:    0.7552\n",
      "F1-score:  0.7531\n",
      "Tiempo de entrenamiento: 528.41 segundos\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_reales, predicciones)\n",
    "precision = precision_score(y_reales, predicciones, average='macro')\n",
    "recall = recall_score(y_reales, predicciones, average='macro')\n",
    "f1 = f1_score(y_reales, predicciones, average='macro')\n",
    "\n",
    "print(\"\\n Resultados del modelo:\")\n",
    "print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"F1-score:  {f1:.4f}\")\n",
    "print(f\"Tiempo de entrenamiento: {tiempo_entrenamiento:.2f} segundos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createMLPClassifier(X, y, x_test, y_test, capas, activaciones, alpha=0.1, epochs=5):\n",
    "    \n",
    "    assert len(capas) == len(activaciones) + 1, \"N煤mero de activaciones debe coincidir con n煤mero de capas\"\n",
    "\n",
    "    n_clases = len(np.unique(y))\n",
    "    perceptron = PerceptronMulticapa(capas=capas, activaciones=activaciones, alpha=0.01)\n",
    "\n",
    "    start_time = time.perf_counter()\n",
    "    perceptron.entrenar(X, np.eye(n_clases)[y], epochs=epochs)\n",
    "    end_time = time.perf_counter()\n",
    "    \n",
    "    # Hacer predicciones sobre el conjunto de prueba\n",
    "    predicciones = []\n",
    "    for i in range(len(x_test)):\n",
    "        prediccion = perceptron.predecir(x_test[i])\n",
    "        prediccion_clase = np.argmax(prediccion)\n",
    "        predicciones.append(prediccion_clase)\n",
    "    \n",
    "    # Calcular la precisi贸n de las predicciones\n",
    "    precision = precision_score(y_test, predicciones, average='macro')\n",
    "    recall = recall_score(y_test , predicciones, average='macro')\n",
    "    f1 = f1_score(y_test, predicciones, average='macro')\n",
    "    accuracy = accuracy_score(y_test, predicciones)\n",
    "    print(f\"Precisi贸n: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"F1: {f1}\")\n",
    "    print(f\"Exactitud: {accuracy}\")\n",
    "    print(f\"Tiempo de entrenamiento: {end_time - start_time}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP con Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.InputLayer(shape=[784]))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(20, activation=\"sigmoid\"))\n",
    "model.add(tf.keras.layers.Dense(61, activation=\"sigmoid\"))\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicciones:  [0 2 1 1 0 1 0 0 2 1 2 2 2 1 0 0 0 1 1 2 0 2 1 2 2 1 1 0 2 0]\n",
      "Valor real  :  [0 2 1 1 0 1 0 0 2 1 2 2 2 1 0 0 0 1 1 2 0 2 1 2 2 1 1 0 2 0]\n",
      "Precisi贸n: 1.00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[10,  0,  0],\n",
       "       [ 0, 10,  0],\n",
       "       [ 0,  0, 10]], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=tf.keras.optimizers.SGD(learning_rate=0.001), metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.perf_counter()\n",
    "history = model.fit(X_entrenamiento, y_entrenamiento, epochs=10)\n",
    "end_time = time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predictions = model.predict(X_prueba)\n",
    "model_predictions = model_predictions.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = precision_score(y_prueba, model_predictions, average='macro')\n",
    "recall = recall_score(y_prueba , model_predictions, average='macro')\n",
    "f1 = f1_score(y_prueba, model_predictions, average='macro')\n",
    "accuracy = accuracy_score(y_prueba, model_predictions)\n",
    "print(f\"Precisi贸n: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1: {f1}\")\n",
    "print(f\"Exactitud: {accuracy}\")\n",
    "print(f\"Tiempo de entrenamiento: {end_time - start_time}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
